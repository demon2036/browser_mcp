#!/usr/bin/env python3
import asyncio
from playwright.async_api import async_playwright
from pathlib import Path
import re

browser = None
context = None
page = None
session_links = {}


async def navigate(url):
    """å¯¼èˆªåˆ°URLå¹¶æå–å¯äº¤äº’å…ƒç´ """
    global browser, context, page, session_links

    if not browser:
        playwright = await async_playwright().start()
        browser = await playwright.chromium.launch(
            headless=True,
            args=[
                '--no-sandbox',
                '--disable-setuid-sandbox',
                '--disable-blink-features=AutomationControlled',
                '--disable-features=IsolateOrigins,site-per-process'
            ]
        )
        context = await browser.new_context(
            viewport={"width": 1920, "height": 1080},
            user_agent="Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36",
            locale='zh-CN',
            timezone_id='Asia/Shanghai',
            accept_downloads=True,
            extra_http_headers={
                'Accept-Language': 'zh-CN,zh;q=0.9,en;q=0.8',
                'Accept': 'text/html,application/xhtml+xml,application/xml;q=0.9,image/webp,*/*;q=0.8'
            }
        )

        # æ·»åŠ åˆå§‹åŒ–è„šæœ¬æ¥éšè—è‡ªåŠ¨åŒ–ç‰¹å¾
        await context.add_init_script("""
            Object.defineProperty(navigator, 'webdriver', {
                get: () => undefined
            });
            Object.defineProperty(navigator, 'plugins', {
                get: () => [1, 2, 3, 4, 5]
            });
            window.chrome = {
                runtime: {}
            };
        """)

        page = await context.new_page()

    await page.goto(url, wait_until="domcontentloaded")
    await page.wait_for_timeout(3000)

    # æ‰§è¡Œå…ƒç´ åˆ†æ
    index_js = Path("index.js").read_text()
    result = await page.evaluate(f"""
        const analyzePage = {index_js};
        analyzePage({{
            doHighlightElements: false,
            focusHighlightIndex: -1,
            viewportExpansion: 100,
            debugMode: false
        }});
    """)

    # æå–å¯äº¤äº’å…ƒç´ 
    interactive = [node for _, node in result['map'].items()
                   if isinstance(node, dict) and node.get('isInteractive')]

    links = []
    session_links.clear()

    for i, node in enumerate(interactive, 1):
        tag = node.get('tagName', 'element')
        text = ''

        if children := node.get('children'):
            if child := result['map'].get(children[0]):
                if child.get('type') == 'TEXT_NODE':
                    text = f" | {child.get('text', '')}"

        attrs = node.get('attributes', {})
        detail = attrs.get('href', '') or attrs.get('class', '')[:30]
        if detail:
            detail = f" â†’ {detail}"

        display_text = f"{i}. {tag}{detail}{text}"[:200]
        links.append(display_text)
        session_links[i] = node.get('xpath', '')

    return {
        "url": page.url,
        "title": await page.title(),
        "links": links
    }


async def click_element(element_number):
    """ç‚¹å‡»æŒ‡å®šç¼–å·çš„å…ƒç´ """
    if element_number not in session_links:
        return {"error": f"æ— æ•ˆå…ƒç´ ç¼–å·ï¼Œå¯ç”¨èŒƒå›´ï¼š1-{len(session_links)}"}

    xpath = session_links[element_number]
    download_info = None
    download_urls = []

    # ç›‘å¬æ‰€æœ‰é¡µé¢çš„ä¸‹è½½äº‹ä»¶
    async def handle_download(download):
        nonlocal download_info
        download_info = {
            "filename": download.suggested_filename,
            "url": download.url
        }
        print(f"\nğŸ”½ æ£€æµ‹åˆ°ä¸‹è½½: {download.suggested_filename}")
        print(f"   ä¸‹è½½URL: {download.url}")
        # ä¿å­˜æ–‡ä»¶
        await download.save_as(f"/tmp/{download.suggested_filename}")
        print(f"   å·²ä¿å­˜åˆ°: /tmp/{download.suggested_filename}")

    # ç›‘å¬ç½‘ç»œå“åº”
    async def handle_response(response):
        url = response.url
        if any(ext in url.lower() for ext in ['.dmg', '.exe', '.zip', '.pkg']) or 'download' in url.lower():
            if 'trace.qq.com' not in url:  # æ’é™¤è·Ÿè¸ªè¯·æ±‚
                download_urls.append(url)
                print(f"\nğŸ“¡ æ£€æµ‹åˆ°ä¸‹è½½URL: {url}")

    # ç›‘å¬æ–°é¡µé¢
    async def handle_page(new_page):
        print(f"\nğŸ”„ æ–°é¡µé¢æ‰“å¼€: {new_page.url}")
        new_page.on("download", handle_download)
        new_page.on("response", handle_response)

        # ç­‰å¾…æ–°é¡µé¢å¯èƒ½çš„ä¸‹è½½
        await new_page.wait_for_timeout(3000)

    # è®¾ç½®ç›‘å¬å™¨
    page.on("download", handle_download)
    page.on("response", handle_response)
    context.on("page", handle_page)

    # è®°å½•å½“å‰é¡µé¢æ•°
    pages_before = len(context.pages)

    # æ‰“å°ç‚¹å‡»å‰çš„å…ƒç´ ä¿¡æ¯
    element = page.locator(f'xpath={xpath}').first
    print(f"\nå‡†å¤‡ç‚¹å‡»å…ƒç´  #{element_number}: {xpath}")
    try:
        text = await element.inner_text()
        print(f"å…ƒç´ æ–‡æœ¬: {text}")
    except:
        pass

    # ç‚¹å‡»å…ƒç´ 
    await element.click()
    print("ç­‰å¾…å“åº”...")
    await page.wait_for_timeout(5000)

    # æ£€æŸ¥æ–°é¡µé¢
    if len(context.pages) > pages_before:
        new_pages = context.pages[pages_before:]
        for new_page in new_pages:
            print(f"\næ£€æŸ¥æ–°é¡µé¢: {new_page.url}")

            # å°è¯•ä»æ–°é¡µé¢æå–ä¸‹è½½é“¾æ¥
            try:
                # æŸ¥æ‰¾æ‰€æœ‰é“¾æ¥
                links = await new_page.locator('a[href*=".dmg"], a[href*="download"]').all()
                for link in links:
                    href = await link.get_attribute('href')
                    if href and '.dmg' in href:
                        print(f"æ‰¾åˆ°ä¸‹è½½é“¾æ¥: {href}")
                        download_urls.append(href)
            except:
                pass

    # å¦‚æœæ²¡æœ‰è‡ªåŠ¨ä¸‹è½½ï¼Œå°è¯•å…¶ä»–æ–¹æ³•
    if not download_info and not download_urls:
        print("\nå°è¯•æ‰§è¡Œé¡µé¢JavaScriptè·å–ä¸‹è½½é“¾æ¥...")
        try:
            # å°è¯•è·å–é¡µé¢ä¸­çš„ä¸‹è½½é“¾æ¥
            download_url = await page.evaluate("""
                () => {
                    // æŸ¥æ‰¾åŒ…å«ä¸‹è½½é“¾æ¥çš„å…ƒç´ 
                    const links = document.querySelectorAll('a[href*=".dmg"], a[href*="download"]');
                    for (let link of links) {
                        if (link.href && link.href.includes('.dmg')) {
                            return link.href;
                        }
                    }

                    // æ£€æŸ¥æ˜¯å¦æœ‰ä¸‹è½½ç›¸å…³çš„å…¨å±€å˜é‡
                    if (window.downloadUrl) return window.downloadUrl;
                    if (window.download_url) return window.download_url;
                    if (window.macDownloadUrl) return window.macDownloadUrl;

                    // æŸ¥æ‰¾onclickä¸­çš„ä¸‹è½½é“¾æ¥
                    const elements = document.querySelectorAll('[onclick*="download"], [onclick*=".dmg"]');
                    for (let el of elements) {
                        const match = el.onclick.toString().match(/(https?:\/\/[^\s'"]+\.dmg)/);
                        if (match) return match[1];
                    }

                    return null;
                }
            """)

            if download_url:
                print(f"ä»é¡µé¢æå–åˆ°ä¸‹è½½é“¾æ¥: {download_url}")
                download_urls.append(download_url)
        except Exception as e:
            print(f"JavaScriptæ‰§è¡Œå¤±è´¥: {e}")

    # æ¸…ç†ç›‘å¬å™¨
    page.remove_listener("download", handle_download)
    page.remove_listener("response", handle_response)
    context.remove_listener("page", handle_page)

    # å¦‚æœæ•è·åˆ°ä¸‹è½½URLä½†æ²¡æœ‰è§¦å‘ä¸‹è½½ï¼Œå°è¯•ç›´æ¥ä¸‹è½½
    if not download_info and download_urls:
        print(f"\næœªè§¦å‘æ ‡å‡†ä¸‹è½½ï¼Œå°è¯•ç›´æ¥è®¿é—®ä¸‹è½½é“¾æ¥...")
        for url in download_urls:
            if '.dmg' in url:
                try:
                    print(f"å°è¯•ä¸‹è½½: {url}")
                    # åˆ›å»ºæ–°é¡µé¢è®¿é—®ä¸‹è½½é“¾æ¥
                    download_page = await context.new_page()
                    download_page.on("download", handle_download)

                    await download_page.goto(url)
                    await download_page.wait_for_timeout(3000)

                    if not download_info:
                        # å¦‚æœè¿˜æ˜¯æ²¡æœ‰ä¸‹è½½ï¼Œä½¿ç”¨fetchè·å–
                        print("ä½¿ç”¨page.evaluateä¸‹è½½...")
                        await download_page.evaluate(f"""
                            (url) => {{
                                const a = document.createElement('a');
                                a.href = url;
                                a.download = url.split('/').pop();
                                document.body.appendChild(a);
                                a.click();
                                document.body.removeChild(a);
                            }}
                        """, url)
                        await download_page.wait_for_timeout(3000)

                    await download_page.close()
                    if download_info:
                        break
                except Exception as e:
                    print(f"ä¸‹è½½å¤±è´¥: {e}")

    # é‡æ–°åˆ†æé¡µé¢
    result = await navigate(page.url)

    response = {
        "action_type": "download" if download_info else "no_download",
        "url": result["url"],
        "title": result["title"],
        "links": result["links"]
    }

    if download_info:
        response["download_info"] = download_info
    elif download_urls:
        response["download_urls"] = download_urls
        print(f"\nâš ï¸  æ•è·åˆ°{len(download_urls)}ä¸ªä¸‹è½½é“¾æ¥ä½†æœªèƒ½è‡ªåŠ¨ä¸‹è½½")
        print("ä½ å¯ä»¥æ‰‹åŠ¨ä¸‹è½½è¿™äº›é“¾æ¥ï¼š")
        for url in download_urls:
            if '.dmg' in url:
                print(f"  wget '{url}'")

    return response


async def main():
    # å¯¼èˆªåˆ°QQæµè§ˆå™¨Macé¡µé¢
    res = await navigate("https://aqllq.sengfeng.cn/channel_4.html?wordId=1170163895025&creativeid=123115745105&bfsemuserid=17022&pid=sembd102615&bd_vid=11092662730189734840")
    print(f"é¡µé¢: {res['title']}")
    print(f"æ‰¾åˆ° {len(res['links'])} ä¸ªå¯äº¤äº’å…ƒç´ \n")
    for link in res['links'][:20]:
        print(link)

    # ç‚¹å‡»ç¬¬7ä¸ªå…ƒç´ ï¼ˆç«‹å³ä¸‹è½½ï¼‰
    print("\nç‚¹å‡»å…ƒç´  #7...")
    res = await click_element(7)
    print(f"\næ“ä½œç±»å‹: {res['action_type']}")
    print(f"å½“å‰é¡µé¢: {res['title']}")

    await browser.close()


if __name__ == "__main__":
    asyncio.run(main())